# ResNet18 ONNX æ¨¡å‹å‡†å¤‡æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•è·å–ã€è½¬æ¢å’Œå‡†å¤‡ResNet18 ONNXæ¨¡å‹æ–‡ä»¶ï¼Œç”¨äºWebGPU + ONNX Runtime Webé¡¹ç›®ã€‚

## ğŸ“‹ ç›®å½•

- [æ¨¡å‹è·å–æ–¹æ³•](#æ¨¡å‹è·å–æ–¹æ³•)
- [æ¨¡å‹è½¬æ¢æ­¥éª¤](#æ¨¡å‹è½¬æ¢æ­¥éª¤)
- [æ¨¡å‹ä¼˜åŒ–](#æ¨¡å‹ä¼˜åŒ–)
- [æ¨¡å‹éªŒè¯](#æ¨¡å‹éªŒè¯)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## ğŸ¯ æ¨¡å‹è·å–æ–¹æ³•

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¨èï¼‰

#### 1. ä»ONNX Model Zooè·å–

ONNX Model Zooæä¾›äº†å¤§é‡é¢„è®­ç»ƒçš„ONNXæ¨¡å‹ï¼ŒåŒ…æ‹¬ResNet18ï¼š

```bash
# å…‹éš†ONNX Model Zooä»“åº“
git clone https://github.com/onnx/models.git
cd models/vision/classification/resnet

# ä¸‹è½½ResNet18æ¨¡å‹
wget https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet18-v1-7.onnx
```

#### 2. ä»Hugging Faceè·å–

```python
from transformers import AutoFeatureExtractor, AutoModelForImageClassification
import torch

# åŠ è½½é¢„è®­ç»ƒçš„ResNet18æ¨¡å‹
model_name = "microsoft/resnet-18"
feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)
model = AutoModelForImageClassification.from_pretrained(model_name)

# è½¬æ¢ä¸ºONNXæ ¼å¼
dummy_input = torch.randn(1, 3, 224, 224)
torch.onnx.export(
    model,
    dummy_input,
    "resnet18.onnx",
    export_params=True,
    opset_version=11,
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={'input': {0: 'batch_size'},
                  'output': {0: 'batch_size'}}
)
```

### æ–¹æ³•äºŒï¼šä»PyTorchè½¬æ¢ ï¼ˆæœ¬é¡¹ç›®ç”¨çš„æ­¤æ–¹æ³•ï¼‰

#### 1. å®‰è£…ä¾èµ–

```bash
pip install torch torchvision onnx onnxruntime
```

#### 2. è½¬æ¢è„šæœ¬

åˆ›å»º `convert_resnet18.py` æ–‡ä»¶ï¼š

```python
import torch
import torchvision.models as models
import torch.nn as nn

def convert_resnet18_to_onnx():
    """å°†PyTorch ResNet18æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼"""
    
    # åŠ è½½é¢„è®­ç»ƒçš„ResNet18æ¨¡å‹
    model = models.resnet18(pretrained=True)
    model.eval()
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    dummy_input = torch.randn(1, 3, 224, 224)
    
    # å¯¼å‡ºä¸ºONNX
    torch.onnx.export(
        model,
        dummy_input,
        "resnet18.onnx",
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'},
                      'output': {0: 'batch_size'}}
    )
    
    print("ResNet18æ¨¡å‹å·²æˆåŠŸè½¬æ¢ä¸ºONNXæ ¼å¼")

if __name__ == "__main__":
    convert_resnet18_to_onnx()
```

è¿è¡Œè½¬æ¢è„šæœ¬ï¼š

```bash
python convert_resnet18.py
```

### æ–¹æ³•ä¸‰ï¼šä½¿ç”¨TensorFlow/Kerasè½¬æ¢

#### 1. å®‰è£…ä¾èµ–

```bash
pip install tensorflow onnx tf2onnx
```

#### 2. è½¬æ¢è„šæœ¬

```python
import tensorflow as tf
import tf2onnx

def convert_keras_resnet18_to_onnx():
    """å°†Keras ResNet18æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼"""
    
    # åŠ è½½é¢„è®­ç»ƒçš„ResNet18æ¨¡å‹
    model = tf.keras.applications.ResNet50(weights='imagenet')
    
    # è½¬æ¢ä¸ºONNX
    onnx_model, _ = tf2onnx.convert.from_keras(model, output_path="resnet18.onnx")
    
    print("ResNet18æ¨¡å‹å·²æˆåŠŸè½¬æ¢ä¸ºONNXæ ¼å¼")

if __name__ == "__main__":
    convert_keras_resnet18_to_onnx()
```

## ğŸ”§ æ¨¡å‹è½¬æ¢æ­¥éª¤

### æ­¥éª¤1ï¼šç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv onnx_env
source onnx_env/bin/activate  # Linux/Mac
# æˆ–
onnx_env\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install torch torchvision onnx onnxruntime pillow numpy
```

### æ­¥éª¤2ï¼šæ¨¡å‹è½¬æ¢

ä½¿ç”¨æä¾›çš„è½¬æ¢è„šæœ¬ï¼š

```python
# convert_model.py
import torch
import torchvision.models as models
import torch.nn as nn
from torchvision import transforms
import onnx
import onnxruntime
import numpy as np
from PIL import Image

class ResNet18Converter:
    def __init__(self):
        self.model = None
        self.transform = None
        
    def load_pretrained_model(self):
        """åŠ è½½é¢„è®­ç»ƒçš„ResNet18æ¨¡å‹"""
        self.model = models.resnet18(pretrained=True)
        self.model.eval()
        
        # å®šä¹‰å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        print("é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å®Œæˆ")
    
    def convert_to_onnx(self, output_path="resnet18.onnx"):
        """è½¬æ¢ä¸ºONNXæ ¼å¼"""
        if self.model is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ¨¡å‹")
        
        # åˆ›å»ºç¤ºä¾‹è¾“å…¥
        dummy_input = torch.randn(1, 3, 224, 224)
        
        # å¯¼å‡ºä¸ºONNX
        torch.onnx.export(
            self.model,
            dummy_input,
            output_path,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={'input': {0: 'batch_size'},
                          'output': {0: 'batch_size'}}
        )
        
        print(f"æ¨¡å‹å·²è½¬æ¢ä¸ºONNXæ ¼å¼: {output_path}")
    
    def validate_onnx_model(self, onnx_path="resnet18.onnx"):
        """éªŒè¯ONNXæ¨¡å‹"""
        # æ£€æŸ¥ONNXæ¨¡å‹
        onnx_model = onnx.load(onnx_path)
        onnx.checker.check_model(onnx_model)
        print("ONNXæ¨¡å‹éªŒè¯é€šè¿‡")
        
        # æµ‹è¯•æ¨ç†
        ort_session = onnxruntime.InferenceSession(onnx_path)
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = np.random.randn(1, 3, 224, 224).astype(np.float32)
        
        # è¿è¡Œæ¨ç†
        ort_inputs = {ort_session.get_inputs()[0].name: test_input}
        ort_outputs = ort_session.run(None, ort_inputs)
        
        print(f"æ¨ç†æµ‹è¯•æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {ort_outputs[0].shape}")
        return True

def main():
    converter = ResNet18Converter()
    
    # åŠ è½½æ¨¡å‹
    converter.load_pretrained_model()
    
    # è½¬æ¢ä¸ºONNX
    converter.convert_to_onnx()
    
    # éªŒè¯æ¨¡å‹
    converter.validate_onnx_model()
    
    print("æ¨¡å‹è½¬æ¢å’ŒéªŒè¯å®Œæˆï¼")

if __name__ == "__main__":
    main()
```

### æ­¥éª¤3ï¼šè¿è¡Œè½¬æ¢

```bash
python convert_model.py
```

## âš¡ æ¨¡å‹ä¼˜åŒ–

### 1. æ¨¡å‹é‡åŒ–

```python
import onnx
from onnxruntime.quantization import quantize_dynamic

def quantize_model(input_path, output_path):
    """åŠ¨æ€é‡åŒ–æ¨¡å‹ä»¥å‡å°æ–‡ä»¶å¤§å°"""
    quantize_dynamic(
        model_input=input_path,
        model_output=output_path,
        weight_type=onnx.TensorProto.INT8
    )
    print(f"æ¨¡å‹é‡åŒ–å®Œæˆ: {output_path}")

# ä½¿ç”¨ç¤ºä¾‹
quantize_model("resnet18.onnx", "resnet18_quantized.onnx")
```

### 2. æ¨¡å‹ç®€åŒ–

```python
import onnxsim
import onnx

def simplify_model(input_path, output_path):
    """ç®€åŒ–ONNXæ¨¡å‹"""
    # åŠ è½½æ¨¡å‹
    model = onnx.load(input_path)
    
    # ç®€åŒ–æ¨¡å‹
    simplified_model, check = onnxsim.simplify(model)
    
    if check:
        onnx.save(simplified_model, output_path)
        print(f"æ¨¡å‹ç®€åŒ–å®Œæˆ: {output_path}")
    else:
        print("æ¨¡å‹ç®€åŒ–å¤±è´¥")

# ä½¿ç”¨ç¤ºä¾‹
simplify_model("resnet18.onnx", "resnet18_simplified.onnx")
```

### 3. æ¨¡å‹å‰ªæ

```python
def create_optimized_model():
    """åˆ›å»ºä¼˜åŒ–ç‰ˆæœ¬çš„æ¨¡å‹"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡å‹å‰ªæã€çŸ¥è¯†è’¸é¦ç­‰ä¼˜åŒ–æŠ€æœ¯
    pass
```

## âœ… æ¨¡å‹éªŒè¯

### 1. åŸºæœ¬éªŒè¯

```python
def validate_model_basic(onnx_path):
    """åŸºæœ¬æ¨¡å‹éªŒè¯"""
    import onnx
    
    # åŠ è½½æ¨¡å‹
    model = onnx.load(onnx_path)
    
    # æ£€æŸ¥æ¨¡å‹ç»“æ„
    onnx.checker.check_model(model)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    print(f"æ¨¡å‹è¾“å…¥: {[input.name for input in model.graph.input]}")
    print(f"æ¨¡å‹è¾“å‡º: {[output.name for input in model.graph.output]}")
    print(f"æ¨¡å‹æ“ä½œæ•°: {len(model.graph.node)}")
    
    return True
```

### 2. æ¨ç†éªŒè¯

```python
def validate_model_inference(onnx_path, test_image_path=None):
    """æ¨ç†éªŒè¯"""
    import onnxruntime
    import numpy as np
    from PIL import Image
    
    # åˆ›å»ºæ¨ç†ä¼šè¯
    session = onnxruntime.InferenceSession(onnx_path)
    
    # å‡†å¤‡æµ‹è¯•è¾“å…¥
    if test_image_path:
        # ä½¿ç”¨çœŸå®å›¾åƒ
        image = Image.open(test_image_path)
        # é¢„å¤„ç†å›¾åƒ...
        input_data = preprocess_image(image)
    else:
        # ä½¿ç”¨éšæœºæ•°æ®
        input_data = np.random.randn(1, 3, 224, 224).astype(np.float32)
    
    # è¿è¡Œæ¨ç†
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name
    
    outputs = session.run([output_name], {input_name: input_data})
    
    print(f"æ¨ç†æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {outputs[0].shape}")
    print(f"è¾“å‡ºèŒƒå›´: [{outputs[0].min():.4f}, {outputs[0].max():.4f}]")
    
    return outputs[0]

def preprocess_image(image):
    """å›¾åƒé¢„å¤„ç†"""
    # è¿™é‡Œå®ç°ä¸è®­ç»ƒæ—¶ç›¸åŒçš„é¢„å¤„ç†é€»è¾‘
    # åŒ…æ‹¬ç¼©æ”¾ã€å½’ä¸€åŒ–ç­‰
    pass
```

### 3. æ€§èƒ½æµ‹è¯•

```python
def benchmark_model(onnx_path, num_runs=100):
    """æ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    import onnxruntime
    import time
    import numpy as np
    
    session = onnxruntime.InferenceSession(onnx_path)
    input_name = session.get_inputs()[0].name
    
    # é¢„çƒ­
    dummy_input = np.random.randn(1, 3, 224, 224).astype(np.float32)
    for _ in range(10):
        session.run(None, {input_name: dummy_input})
    
    # æ€§èƒ½æµ‹è¯•
    times = []
    for _ in range(num_runs):
        start_time = time.time()
        session.run(None, {input_name: dummy_input})
        end_time = time.time()
        times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
    
    avg_time = np.mean(times)
    std_time = np.std(times)
    
    print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f}ms Â± {std_time:.2f}ms")
    print(f"æœ€å°æ¨ç†æ—¶é—´: {np.min(times):.2f}ms")
    print(f"æœ€å¤§æ¨ç†æ—¶é—´: {np.max(times):.2f}ms")
    
    return avg_time, std_time
```

## ğŸ“ æ–‡ä»¶ç»„ç»‡

å°†è½¬æ¢å¥½çš„æ¨¡å‹æ–‡ä»¶æ”¾ç½®åœ¨é¡¹ç›®çš„æ­£ç¡®ä½ç½®ï¼š

```
webgpu-demo/
â”œâ”€â”€ public/
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ resnet18.onnx              # åŸå§‹æ¨¡å‹
â”‚       â”œâ”€â”€ resnet18_simplified.onnx   # ç®€åŒ–ç‰ˆæœ¬
â”‚       â”œâ”€â”€ resnet18_quantized.onnx    # é‡åŒ–ç‰ˆæœ¬
â”‚       â””â”€â”€ imagenet_classes.json      # ç±»åˆ«æ ‡ç­¾
```

## ğŸ” å¸¸è§é—®é¢˜

### Q1: æ¨¡å‹æ–‡ä»¶å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ

**A**: å¯ä»¥å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
- ä½¿ç”¨æ¨¡å‹é‡åŒ–å‡å°æ–‡ä»¶å¤§å°
- ä½¿ç”¨æ¨¡å‹ç®€åŒ–å»é™¤å†—ä½™æ“ä½œ
- è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹æ¶æ„

### Q2: æ¨ç†é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**A**: å¯ä»¥å°è¯•ä»¥ä¸‹ä¼˜åŒ–ï¼š
- ä½¿ç”¨WebGPUæ‰§è¡Œæä¾›è€…
- å¯ç”¨å›¾ä¼˜åŒ–
- ä½¿ç”¨é‡åŒ–æ¨¡å‹
- è°ƒæ•´æ‰¹å¤„ç†å¤§å°

### Q3: æ¨¡å‹åŠ è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
- æ¨¡å‹æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- æ¨¡å‹æ ¼å¼æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ONNXæ ¼å¼
- æµè§ˆå™¨æ˜¯å¦æ”¯æŒWebGPU
- ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸

### Q4: å¦‚ä½•æ·»åŠ æ–°çš„æ¨¡å‹ï¼Ÿ

**A**: æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ï¼š
1. å°†ONNXæ¨¡å‹æ–‡ä»¶æ”¾å…¥ `public/models/` ç›®å½•
2. åœ¨ `ModelManager.getAvailableModels()` ä¸­æ·»åŠ æ¨¡å‹é…ç½®
3. å‡†å¤‡å¯¹åº”çš„ç±»åˆ«æ ‡ç­¾æ–‡ä»¶
4. æµ‹è¯•æ¨¡å‹åŠ è½½å’Œæ¨ç†

## ğŸ“š å‚è€ƒèµ„æº

- [ONNXå®˜æ–¹æ–‡æ¡£](https://onnx.ai/)
- [ONNX Model Zoo](https://github.com/onnx/models)
- [PyTorch ONNXå¯¼å‡ºæŒ‡å—](https://pytorch.org/docs/stable/onnx.html)
- [ONNX Runtime Webæ–‡æ¡£](https://github.com/microsoft/onnxruntime/tree/master/js/web)

## ğŸ› ï¸ è‡ªåŠ¨åŒ–è„šæœ¬

é¡¹ç›®å·²ç»æä¾›äº†å®Œæ•´çš„è‡ªåŠ¨åŒ–è„šæœ¬ï¼Œä½äº `pyScript/` ç›®å½•ä¸­ï¼š

### ç»Ÿä¸€ç®¡ç†è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# æ‰§è¡Œæ‰€æœ‰æ­¥éª¤
python pyScript/manage_models.py

# æ‰§è¡Œç‰¹å®šæ­¥éª¤
python pyScript/manage_models.py --step export    # åªå¯¼å‡ºæ¨¡å‹
python pyScript/manage_models.py --step simplify  # åªç®€åŒ–æ¨¡å‹
python pyScript/manage_models.py --step test      # åªæµ‹è¯•æ¨¡å‹
python pyScript/manage_models.py --step labels    # åªä¸‹è½½æ ‡ç­¾
python pyScript/manage_models.py --step config    # åªåˆ›å»ºé…ç½®

# è·³è¿‡æµ‹è¯•æ­¥éª¤
python pyScript/manage_models.py --skip-test
```

### å•ç‹¬è„šæœ¬

```bash
# å¯¼å‡ºæ¨¡å‹
python pyScript/getOnnx.py

# ç®€åŒ–æ¨¡å‹
python pyScript/getSimplifiedOnnx.py

# æµ‹è¯•æ¨¡å‹
python pyScript/testOnnx.py
```

### å¿«é€Ÿå¼€å§‹

```bash
# ä¸€é”®å®Œæˆæ‰€æœ‰å‡†å¤‡å·¥ä½œ
python scripts/quick_start.py
```

è¿™äº›è„šæœ¬ä¼šè‡ªåŠ¨å¤„ç†æ¨¡å‹å¯¼å‡ºã€ç®€åŒ–ã€æµ‹è¯•ã€æ ‡ç­¾ä¸‹è½½ç­‰æ‰€æœ‰æ­¥éª¤ï¼Œè®©æ‚¨å¿«é€Ÿå¼€å§‹é¡¹ç›®å¼€å‘ï¼ 