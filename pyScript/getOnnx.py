#!/usr/bin/env python3
"""
ResNet18 ONNX æ¨¡å‹å¯¼å‡ºè„šæœ¬
å°†é¢„è®­ç»ƒçš„PyTorch ResNet18æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼
"""

import torch
import torch.onnx
import torchvision.models as models
import os
import sys
from pathlib import Path

def export_resnet18_to_onnx(output_path="resnet18.onnx", opset_version=11):
    """
    å¯¼å‡ºResNet18æ¨¡å‹ä¸ºONNXæ ¼å¼
    
    Args:
        output_path (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
        opset_version (int): ONNXç®—å­ç‰ˆæœ¬
    """
    try:
        print("ğŸ”„ å¼€å§‹å¯¼å‡ºResNet18æ¨¡å‹...")
        
        # 1. åŠ è½½é¢„è®­ç»ƒ ResNet18
        print("ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
        model = models.resnet18(pretrained=True)
        model.eval()  # æ¨ç†æ¨¡å¼
        print("âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å®Œæˆ")
        
        # 2. åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿè¾“å…¥ï¼ˆbatch_size=1, 3é€šé“ï¼Œ224x224 å›¾åƒï¼‰
        dummy_input = torch.randn(1, 3, 224, 224)
        print(f"ğŸ“Š è¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
        
        # 3. å¯¼å‡ºä¸º ONNX
        print("ğŸ”„ æ­£åœ¨å¯¼å‡ºä¸ºONNXæ ¼å¼...")
        torch.onnx.export(
            model,                      # æ¨¡å‹
            dummy_input,                # æ¨¡æ‹Ÿè¾“å…¥
            output_path,                # è¾“å‡ºæ–‡ä»¶å
            export_params=True,         # ä¿å­˜è®­ç»ƒå¥½çš„æƒé‡
            opset_version=opset_version, # ONNX ç®—å­ç‰ˆæœ¬
            do_constant_folding=True,   # å¸¸é‡æŠ˜å ä¼˜åŒ–
            input_names=['input'],      # è¾“å…¥å
            output_names=['output'],    # è¾“å‡ºå
            dynamic_axes={              # åŠ¨æ€ç»´åº¦æ”¯æŒï¼ˆbatch_size å¯å˜ï¼‰
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
        print(f"âœ… ResNet18 å·²æˆåŠŸå¯¼å‡ºä¸º {output_path}")
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return False

def validate_onnx_model(model_path):
    """
    éªŒè¯ONNXæ¨¡å‹
    
    Args:
        model_path (str): æ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    try:
        import onnx
        
        print(f"ğŸ” éªŒè¯æ¨¡å‹: {model_path}")
        model = onnx.load(model_path)
        onnx.checker.check_model(model)
        
        print("âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡")
        print(f"ğŸ“Š æ¨¡å‹è¾“å…¥: {[input.name for input in model.graph.input]}")
        print(f"ğŸ“Š æ¨¡å‹è¾“å‡º: {[output.name for output in model.graph.output]}")
        print(f"ğŸ“Š æ¨¡å‹æ“ä½œæ•°: {len(model.graph.node)}")
        
        return True
        
    except ImportError:
        print("âš ï¸ æœªå®‰è£…onnxåº“ï¼Œè·³è¿‡æ¨¡å‹éªŒè¯")
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return False

def test_inference(model_path):
    """
    æµ‹è¯•æ¨¡å‹æ¨ç†
    
    Args:
        model_path (str): æ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    try:
        import onnxruntime as ort
        import numpy as np
        
        print(f"ğŸ§ª æµ‹è¯•æ¨ç†: {model_path}")
        
        # åˆ›å»ºæ¨ç†ä¼šè¯
        ort_session = ort.InferenceSession(model_path)
        
        # æ„é€ è¾“å…¥æ•°æ®
        dummy_input = np.random.randn(1, 3, 224, 224).astype(np.float32)
        
        # è¿è¡Œæ¨ç†
        outputs = ort_session.run(None, {"input": dummy_input})
        
        print("âœ… æ¨ç†æµ‹è¯•æˆåŠŸ")
        print(f"ğŸ“Š è¾“å‡ºå½¢çŠ¶: {outputs[0].shape}")
        print(f"ğŸ“Š è¾“å‡ºèŒƒå›´: [{outputs[0].min():.4f}, {outputs[0].max():.4f}]")
        
        return True
        
    except ImportError:
        print("âš ï¸ æœªå®‰è£…onnxruntimeåº“ï¼Œè·³è¿‡æ¨ç†æµ‹è¯•")
        return True
    except Exception as e:
        print(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ResNet18 ONNX æ¨¡å‹å¯¼å‡ºå·¥å…·")
    print("=" * 50)
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    output_dir = Path("../public/models")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "resnet18.onnx"
    
    # å¯¼å‡ºæ¨¡å‹
    if export_resnet18_to_onnx(str(output_path)):
        # éªŒè¯æ¨¡å‹
        validate_onnx_model(str(output_path))
        
        # æµ‹è¯•æ¨ç†
        test_inference(str(output_path))
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ¨¡å‹å¯¼å‡ºå®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {output_path}")
        print("=" * 50)
    else:
        print("\nâŒ æ¨¡å‹å¯¼å‡ºå¤±è´¥ï¼")
        sys.exit(1)

if __name__ == "__main__":
    main()
